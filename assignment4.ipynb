{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import tensorflow and tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\New User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Custom Dataset using tf.data API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Task 1: Create Custom Dataset using tf.data API\n",
    "X_train = [[1,2,3], [4,5,6], [7,8,9], [10,11,12]] # sample data\n",
    "y_train = [0,1,0,1] # sample labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a tf.data.Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "\n",
    "# Shuffle and batch the dataset\n",
    "dataset = dataset.shuffle(buffer_size=len(X_train)).batch(batch_size=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data using tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST Dataset Information:\n",
      "tfds.core.DatasetInfo(\n",
      "    name='mnist',\n",
      "    full_name='mnist/3.0.1',\n",
      "    description=\"\"\"\n",
      "    The MNIST database of handwritten digits.\n",
      "    \"\"\",\n",
      "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
      "    data_dir='C:\\\\Users\\\\New User\\\\tensorflow_datasets\\\\mnist\\\\3.0.1',\n",
      "    file_format=tfrecord,\n",
      "    download_size=Unknown size,\n",
      "    dataset_size=Unknown size,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(28, 28, 1), dtype=uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "    },\n",
      "    citation=\"\"\"@article{lecun2010mnist,\n",
      "      title={MNIST handwritten digit database},\n",
      "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
      "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
      "      volume={2},\n",
      "      year={2010}\n",
      "    }\"\"\",\n",
      ")\n",
      "Size of each split:\n",
      "{}\n",
      "Size of labels:\n",
      "10\n",
      "Labels:\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the MNIST dataset\n",
    "mnist_info = tfds.builder('mnist').info\n",
    "\n",
    "# Print information about the dataset\n",
    "print(\"MNIST Dataset Information:\")\n",
    "print(mnist_info)\n",
    "print(\"Size of each split:\")\n",
    "print(mnist_info.splits)\n",
    "print(\"Size of labels:\")\n",
    "print(mnist_info.features['label'].num_classes)\n",
    "print(\"Labels:\")\n",
    "print(mnist_info.features['label'].names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IMDB Reviews Dataset Information:\n",
      "tfds.core.DatasetInfo(\n",
      "    name='imdb_reviews',\n",
      "    full_name='imdb_reviews/plain_text/1.0.0',\n",
      "    description=\"\"\"\n",
      "    Large Movie Review Dataset. This is a dataset for binary sentiment\n",
      "    classification containing substantially more data than previous benchmark\n",
      "    datasets. We provide a set of 25,000 highly polar movie reviews for training,\n",
      "    and 25,000 for testing. There is additional unlabeled data for use as well.\n",
      "    \"\"\",\n",
      "    config_description=\"\"\"\n",
      "    Plain text\n",
      "    \"\"\",\n",
      "    homepage='http://ai.stanford.edu/~amaas/data/sentiment/',\n",
      "    data_dir='C:\\\\Users\\\\New User\\\\tensorflow_datasets\\\\imdb_reviews\\\\plain_text\\\\1.0.0',\n",
      "    file_format=tfrecord,\n",
      "    download_size=Unknown size,\n",
      "    dataset_size=Unknown size,\n",
      "    features=FeaturesDict({\n",
      "        'label': ClassLabel(shape=(), dtype=int64, num_classes=2),\n",
      "        'text': Text(shape=(), dtype=string),\n",
      "    }),\n",
      "    supervised_keys=('text', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "    },\n",
      "    citation=\"\"\"@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
      "      author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
      "      title     = {Learning Word Vectors for Sentiment Analysis},\n",
      "      booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
      "      month     = {June},\n",
      "      year      = {2011},\n",
      "      address   = {Portland, Oregon, USA},\n",
      "      publisher = {Association for Computational Linguistics},\n",
      "      pages     = {142--150},\n",
      "      url       = {http://www.aclweb.org/anthology/P11-1015}\n",
      "    }\"\"\",\n",
      ")\n",
      "Size of each split:\n",
      "{}\n",
      "Size of labels:\n",
      "2\n",
      "Labels:\n",
      "['neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the IMDB reviews dataset\n",
    "imdb_info = tfds.builder('imdb_reviews').info\n",
    "\n",
    "# Print information about the dataset\n",
    "print(\"\\nIMDB Reviews Dataset Information:\")\n",
    "print(imdb_info)\n",
    "print(\"Size of each split:\")\n",
    "print(imdb_info.splits)\n",
    "print(\"Size of labels:\")\n",
    "print(imdb_info.features['label'].num_classes)\n",
    "print(\"Labels:\")\n",
    "print(imdb_info.features['label'].names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom processing and augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define custom preprocessing and augmentation functions\n",
    "def preprocess(element):\n",
    "    image, label = element\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "Images shape: image\n",
      "Labels: label\n",
      "Batch 2:\n",
      "Images shape: image\n",
      "Labels: label\n",
      "Batch 3:\n",
      "Images shape: image\n",
      "Labels: label\n",
      "Batch 4:\n",
      "Images shape: image\n",
      "Labels: label\n",
      "Batch 5:\n",
      "Images shape: image\n",
      "Labels: label\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Apply custom preprocessing to the MNIST dataset\n",
    "mnist_dataset = tfds.load('mnist', split='train')#.map(preprocess)\n",
    "\n",
    "# Shuffle, batch, and prefetch the dataset\n",
    "mnist_dataset = mnist_dataset.shuffle(buffer_size=10000).batch(batch_size=32).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Iterate over the augmented dataset and list the first 5 batches\n",
    "for i, (images, labels) in enumerate(mnist_dataset.take(5)):\n",
    "    print(f\"Batch {i+1}:\")\n",
    "    print(\"Images shape:\", images)\n",
    "    print(\"Labels:\", labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
